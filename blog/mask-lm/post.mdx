---
title: "Mask-LM 生成影片能力趨近完美 with MAGVIT-V2 by Google & CMU Yu et al."
slug: "mask-lm"
date: "2024-04-06"
hero-image: "./hero.png"
tags: ["java", "python"]
author: "David Vanguard"
---

```python{1-3,6-7,9}
# Python program to check if the input number is odd or even.
# A number is even if division by 2 gives a remainder of 0.
# If the remainder is 1, it is an odd number.

num = int(input("Enter a number: "))
if (num % 2) == 0:
   print("{0} is Even".format(num))
else:
   print("{0} is Odd".format(num))
```

![hero](/hero.png "hero")
![1](/1.png "1")
# SORA引起大家廣泛的討論與注意，其底層架構來自於DiT
 **我愛** **文字** (2024/2月中) OpenAI 的 *SORA*引起大家廣**泛的討論與注意**，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的**競爭對手**還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。

> Hello World

1. First item
2. Second item
3. Third item

生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。

* Item 1
* Item 2
* Item 3

# 生成影片技術
近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與*注意*，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
```c++
backtick.fences('for blocks')
```
*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
## 資料壓縮
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
## h2標題 h2標題1-2
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
# h1標題 h1標題2
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
## h2標題 h2標題2-1
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
## h2標題 h2標題2-3
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
![thesis](https://p2.bahamut.com.tw/B/2KU/41/b3b23338013985df1d4dc836eb1ohqd5.JPG "thesis")
![test](https://p2.bahamut.com.tw/B/2KU/41/b3b23338013985df1d4dc836eb1ohqd5.JPG "test")






# ha
*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
## haha
*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。近日(2024/2月中) OpenAI 的 *SORA*引起大家廣泛的討論與注意，其底層架構來自於*DiT (Diffusion Transformer)*，但其實這個領域的競爭對手還不少，這次要介紹的這篇，使用Mask-LM的生成方式，可以達到最頂尖的FID/FVD分數，兼顧生成品質與生成速度，讓我們一起來看看Google與卡內基美濃大學Yu同學 (原中國北京大學高材生)團隊針對影片生成領域提出了那些SoTA見解。
生成影片技術的本質就是一種資料壓縮，把影片中的每時每刻，每張瞬間的圖片，經由模型映射成如同文字那樣的Token向量，之後就能用LM語言模型相關的技術，把類似的影片藉由Token的組合，經過反向生成 or Decode出來。神經網路能夠用很廉價的方式抽取黑格爾小邏輯裡面所提到的本質，這本質往往具有空間不變性，時間不變性，概念不變性，可以在不同的觸發條件下，像積木一樣，重新做各種排列組合以組成萬物。讓我們抱著期待的心情，看看*MAGVIT*架構能為我們帶來哪些驚喜應用潛能與突破。





```javascript
function hello_world(){
    console.log("Hello, world!");
}
hello_world()
```